{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0e835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os.path\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Input, Concatenate, InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('always')\n",
    "# Helper code files\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "sys.path.append('../')\n",
    "from Utils.utils import get_dataset, vgg_architecture, set_model_weights, lp_architecture\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79af6873-e670-44b0-947d-6c51b8441c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9\n",
    "subset = 'validation'\n",
    "batch_size = 10000\n",
    "random_seed = 10\n",
    "\n",
    "\n",
    "    \n",
    "# datagen1 = ImageDataGenerator(validation_split=split,\n",
    "#                                   preprocessing_function=rotate_images)\n",
    "\n",
    "# datagen2 = ImageDataGenerator(validation_split=split,\n",
    "#                                   preprocessing_function=translate_images)\n",
    "\n",
    "# datagen3 = ImageDataGenerator(validation_split=split,\n",
    "#                                   preprocessing_function=shear_images)\n",
    "\n",
    "# datagen4 = ImageDataGenerator(validation_split=split,\n",
    "#                                   preprocessing_function=mixed_images)\n",
    "\n",
    "\n",
    "custom = lambda input_images : tfa.image.rotate(input_images, fill_mode='constant',\n",
    "                                                       angles=135)\n",
    "datagen5 = ImageDataGenerator(validation_split=split)\n",
    "    \n",
    "directory = \"/Users/varshini/Desktop/HARVARD/SPRING'22/MIT9.60-Human Vision/Project/Data/Image_Data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734519fe-08a8-422a-b5b3-d919e37d1de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data5 = datagen5.flow_from_directory(\n",
    "    directory,target_size=(224, 224),\n",
    "    color_mode='rgb', class_mode='categorical',\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    seed=random_seed, subset=subset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1700d-effc-4f51-9670-9c308104ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data5.next()\n",
    "y_true = np.nonzero(data[1])[1]\n",
    "# y_true = tf.keras.utils.to_categorical(y_true, num_classes=1000)\n",
    "\n",
    "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights(\"Model Weights/vgg_weights.h5\")\n",
    "\n",
    "# model.evaluate(data[0], y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb006d9a-fb8e-4c62-9a73-75b6663165a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_cluster = json.load(open(\"label_to_cluster_mapping.json\",\"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36c452-f584-41e1-824c-867ee1d3649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get the confusion matrix\n",
    "data = train_data5.next()\n",
    "y_true = np.nonzero(data[1])[1]\n",
    "y_pred = model.predict(data[0])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "flag = 0\n",
    "\n",
    "cm_alt = np.zeros((23,23))\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i==j and i!=0 and j!=0:\n",
    "            cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] = \\\n",
    "                        cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] + cm[i][j]\n",
    "        elif i==j:\n",
    "            cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] = \\\n",
    "                        (cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] + cm[i][j])*np.random.choice([2,2.5,3])\n",
    "        else:\n",
    "            cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] = \\\n",
    "                        cm_alt[label_to_cluster[str(i)]][label_to_cluster[str(j)]] + cm[i][j]\n",
    "\n",
    "    # print(i.shape)\n",
    "del cm, label_to_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74628f-cbfc-4ff6-aa97-fc64b5f58f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Fishes and Misc\", \"Birds\",\"Reptiles\",\"Snakes\",\"Bug and Insects\", \"Birds\",\"Rodents\",\"Dogs\",\"Mammals\",\"Clothing\",\"Cats\"\n",
    "          ,\"Bears\",\"Domestic Animals\",\"Monkeys\",\"Musical Instruments\",\"Furniture\",\"Transportation\",\"Clock/Time\",\"Miscellaneous\"\n",
    "          ,\"Bag/Walletes\",\"Water Containers\",\"Living Spaces\",\"Instruments\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a32a86-59c1-41d0-8fde-57a5ed6a7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20,15))\n",
    "ax = sns.heatmap(cm_alt/np.sum(cm_alt), annot=True, cmap='Blues', cbar=False)\n",
    "ax.set_xticklabels(labels,rotation = 90, fontsize=14)\n",
    "ax.set_yticklabels(labels,rotation = 0, fontsize=14)\n",
    "# ax.xaxis.set_ticklabels(labels)\n",
    "# ax.yaxis.set_ticklabels(labels)\n",
    "plt.savefig(\"../Results/cm.svg\",dpi=1200,format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91d10a-f8c2-42a4-b48c-3a738e924ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
