{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0e835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os.path\n",
    "import cv2\n",
    "    \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Input, Concatenate, InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings \n",
    "warnings.filterwarnings('always')\n",
    "from skimage.transform import warp_polar, warp_coords\n",
    "# Helper code files\n",
    "import time\n",
    "sys.path.append('../')\n",
    "from Utils.utils import get_dataset, ssd_architecture, vgg_architecture, set_model_weights\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3aa622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Corresponds to conv10, conv12, conv13\n",
    "out_layer_num = [1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be1834a-4a63-4124-8a47-1c1ff317071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 18:14:07.433671: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-30 18:14:07.433831: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "# #Base convolution for encoder\n",
    "inp, out1 = ssd_architecture(out_layer_num[0])\n",
    "encoder = Model(inputs=inp, outputs=out1, name=\"Encoder\")\n",
    "if os.path.exists(\"Model Weights/encoder_weights.h5\"):\n",
    "    encoder.set_weights(\"Model Weights/encoder_weights.h5\")\n",
    "\n",
    "\n",
    "# Base convolution for decoder\n",
    "inp, out = ssd_architecture(out_layer_num[0], input_shape=(300,300,out1.shape[3]), model_type=\"decoder\")\n",
    "decoder = Model(inputs=inp, outputs=out, name=\"Decoder\")\n",
    "if os.path.exists(\"Model Weights/decoder_weights.h5\"):\n",
    "    decoder.set_weights(\"Model Weights/decoder_weights.h5\")\n",
    "\n",
    "    \n",
    "# #Feature extraction section of LPNet\n",
    "inp, out = vgg_architecture()\n",
    "feature_extractor = Model(inputs=inp, outputs=out, name=\"Feature_Extractor\")\n",
    "if os.path.exists(\"Model Weights/feature_extractor_weights.h5\"):\n",
    "    feature_extractor.set_weights(\"Model Weights/feature_extractor_weights.h5\")\n",
    "else:\n",
    "    feature_extractor = set_model_weights(feature_extractor)\n",
    "\n",
    "del inp, out, out1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a63ca4-4fce-4f11-b62b-cc2a9ce52a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogPolarLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, cx=0, cy=0):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.cx = cx\n",
    "    self.cy = cy\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self.num_outputs])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4c2025-b23b-442f-8149-299a0fb52d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(decoder_out.shape[1]):\n",
    "#     x = decoder_out\n",
    "\n",
    "def inv_log_transform(decoder_out):\n",
    "    decoder_out = np.array(decoder_out)\n",
    "    # for i in range(decoder_out.shape[0]):\n",
    "    x = tf.math.multiply(decoder_out[:,:,:,2],tf.math.cos(decoder_out[:,:,:,1]))\n",
    "    y = tf.math.multiply(decoder_out[:,:,:,2],tf.math.sin(decoder_out[:,:,:,1]))\n",
    "    decoder_out[:,:,:,1] = x\n",
    "    decoder_out[:,:,:,2] = y\n",
    "    return tf.convert_to_tensor(decoder_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c40d81-4fa8-4f5e-bec2-dad1406d4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRIAL FUNCTIONS\n",
    "# # # log_polar_transform = lambda img : warp_polar(image = np.array(img), multichannel=True, output_shape=(300,300))\n",
    "# # # polar_out = tf.function(log_polar_transform)\n",
    "# encoder_transformed_out = tf.map_fn(lambda img : warp_polar(image = np.array(img), channel_axis=2, \n",
    "#                                                             output_shape=(300,300)), enc_output)\n",
    "\n",
    " \n",
    "# decoder_out = decoder(encoder_transformed_out)\n",
    "\n",
    "# decoder_transformed_out = inv_log_transform(decoder_out)\n",
    "\n",
    "# model_predictions = feature_extractor(decoder_transformed_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba4660-f407-45b4-8886-d65b8182a005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1000 classes.\n",
      "\n",
      "EPOCH: 1\n",
      "\tBATCH NUMBER: 1\n",
      "\t\t\tEncoder Output\t\t\t 0.4\n",
      "\t\t\tTransformed Encoder Output\t 123.7\n"
     ]
    }
   ],
   "source": [
    "# GRADIENT TAPE\n",
    "\n",
    "# Algorithm parameters\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metrics = tf.keras.metrics.Accuracy()\n",
    "num_epochs = 10\n",
    "\n",
    "train_data = get_dataset(batch_size, False)\n",
    "# steps_per_epoch = train_data.samples // batch_size\n",
    "steps_per_epoch = 1\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(\"\\nEPOCH:\", i+1)\n",
    "    loss = 0\n",
    "    \n",
    "    for bs in range(steps_per_epoch):\n",
    "        if bs%1==0:\n",
    "            print(\"\\tBATCH NUMBER:\",bs+1)\n",
    "        try:\n",
    "            t1 = train_data.next()\n",
    "        except:\n",
    "            train_data = get_dataset(batch_size, False)\n",
    "            t1 = train_data.next()\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape1, tf.GradientTape(persistent=True) as tape2, tf.GradientTape(persistent=True) as tape3:\n",
    "        # with tf.GradientTape(persistent=True) as tape:\n",
    "            start = time.time()\n",
    "            enc_output = encoder(t1[0])\n",
    "            end = time.time()\n",
    "            print(\"\\t\\t\\tEncoder Output\\t\\t\\t\", round((end-start), 2))\n",
    "            \n",
    "            \n",
    "            # Log-polar transform\n",
    "            start = time.time()\n",
    "            encoder_transformed_out = tf.map_fn(lambda img : warp_polar(image = np.array(img), channel_axis=2, \n",
    "                                                            output_shape=(300,300)), enc_output)\n",
    "            end = time.time()\n",
    "            # del enc_output\n",
    "            print(\"\\t\\t\\tTransformed Encoder Output\\t\", round((end-start), 2))\n",
    "            \n",
    "            \n",
    "            start = time.time()\n",
    "            decoder_out = decoder(encoder_transformed_out)\n",
    "            end = time.time()\n",
    "            print(\"\\t\\t\\tDecoder Output\\t\\t\\t\", round((end-start), 2))\n",
    "            del encoder_transformed_out\n",
    "\n",
    "            # Inverse log-polar transform\n",
    "            start = time.time()\n",
    "            decoder_transformed_out = inv_log_transform(decoder_out)\n",
    "            end = time.time()\n",
    "            print(\"\\t\\t\\tTransformed Decoder Output\\t\", round((end-start), 2))\n",
    "            del decoder_out\n",
    "\n",
    "            start = time.time()\n",
    "            output = feature_extractor(decoder_transformed_out)\n",
    "            end = time.time()\n",
    "            print(\"\\t\\t\\tFeature Extractor\\t\\t\", round((end-start), 2),\"\\n\")\n",
    "            del decoder_transformed_out\n",
    "            \n",
    "            loss+= loss_fn(t1[1], output)\n",
    "            del output\n",
    "            \n",
    "    gradients1 = tape1.gradient(loss, feature_extractor.trainable_weights)\n",
    "    gradients2 = tape1.gradient(loss, decoder.trainable_weights)\n",
    "    gradients3 = tape1.gradient(loss, encoder.trainable_weights)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients1, feature_extractor.trainable_weights))    \n",
    "    optimizer.apply_gradients(zip(gradients2, decoder.trainable_weights))    \n",
    "    optimizer.apply_gradients(zip(gradients3, encoder.trainable_weights))    \n",
    "\n",
    "    feature_extractor.save_weights(\"Model Weights/feature_extractor_weights.h5\")\n",
    "    decoder.save_weights(\"Model Weights/decoder_weights.h5\")\n",
    "    encoder.save_weights(\"Model Weights/encoder_weights.h5\")\n",
    "    clear_output(wait=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13b1ec-5bda-4eaf-9db1-b498f39d721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(Model):\n",
    "  def _init_(self, encoder, decoder, feature_extractor):\n",
    "    super(MainModel, self)._init_()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.feature_extractor = feature_extractor\n",
    "  \n",
    "  def compile(self,optimizer,metrics,loss_fn):\n",
    "    super(MainModel, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "    self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "      t1 = data\n",
    "\n",
    "      with tf.GradientTape() as tape1, tf.GradientTape() as tape2, tf.GradientTape() as tape3:\n",
    "        start = time.time()\n",
    "        enc_output = self.encoder(t1[0])\n",
    "        end = time.time()\n",
    "        print(\"\\t\\t\\tEncoder Output\\t\\t\\t\", round((end-start), 2))\n",
    "        \n",
    "        \n",
    "        # Log-polar transform\n",
    "        start = time.time()\n",
    "        encoder_transformed_out = tf.map_fn(lambda img : warp_polar(image = np.array(img), channel_axis=2, \n",
    "                                                        output_shape=(300,300)), enc_output)\n",
    "        end = time.time()\n",
    "        # del enc_output\n",
    "        print(\"\\t\\t\\tTransformed Encoder Output\\t\", round((end-start), 2))\n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        decoder_out = self.decoder(encoder_transformed_out)\n",
    "        end = time.time()\n",
    "        print(\"\\t\\t\\tDecoder Output\\t\\t\\t\", round((end-start), 2))\n",
    "        del encoder_transformed_out\n",
    "\n",
    "        # Inverse log-polar transform\n",
    "        start = time.time()\n",
    "        decoder_transformed_out = inv_log_transform(decoder_out)\n",
    "        end = time.time()\n",
    "        print(\"\\t\\t\\tTransformed Decoder Output\\t\", round((end-start), 2))\n",
    "        del decoder_out\n",
    "\n",
    "        start = time.time()\n",
    "        output = self.feature_extractor(decoder_transformed_out)\n",
    "        end = time.time()\n",
    "        print(\"\\t\\t\\tFeature Extractor\\t\\t\", round((end-start), 2),\"\\n\")\n",
    "        del decoder_transformed_out\n",
    "        \n",
    "        loss+= loss_fn(t1[1], output)\n",
    "        del output\n",
    "            \n",
    "    gradients1 = tape1.gradient(loss, feature_extractor.trainable_weights)\n",
    "    gradients2 = tape1.gradient(loss, decoder.trainable_weights)\n",
    "    gradients3 = tape1.gradient(loss, encoder.trainable_weights)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients1, feature_extractor.trainable_weights))    \n",
    "    optimizer.apply_gradients(zip(gradients2, decoder.trainable_weights))    \n",
    "    optimizer.apply_gradients(zip(gradients3, encoder.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae41c67-432c-4369-84c5-c5bd09760c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainModel(encoder, decoder, feature_extractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e2f8e-42a7-482c-8898-be7c6bb5354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,metrics,loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139108-e51a-4e5e-be75-53d6c63963f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
